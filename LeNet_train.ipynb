{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LeNet_train.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWZ34FE5dsbz",
        "outputId": "8d97add3-256f-48f4-c095-323905fd034d"
      },
      "source": [
        "!git clone https://github.com/worldstar/ultrasoundSoundAugmentation.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'ultrasoundSoundAugmentation'...\n",
            "remote: Enumerating objects: 82, done.\u001b[K\n",
            "remote: Counting objects: 100% (82/82), done.\u001b[K\n",
            "remote: Compressing objects: 100% (81/81), done.\u001b[K\n",
            "remote: Total 82 (delta 16), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (82/82), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2BPXjRISk_T",
        "outputId": "cb8b02f7-30fe-4135-92cd-582b3dbae4fd"
      },
      "source": [
        "!wget https://github.com/OlafenwaMoses/IdenProf/releases/download/v1.0/idenprof-jpg.zip\r\n",
        "!unzip -qq idenprof-jpg.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-01-26 02:45:06--  https://github.com/OlafenwaMoses/IdenProf/releases/download/v1.0/idenprof-jpg.zip\n",
            "Resolving github.com (github.com)... 192.30.255.113\n",
            "Connecting to github.com (github.com)|192.30.255.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github-production-release-asset-2e65be.s3.amazonaws.com/131628975/f5b4b56a-75bc-11e8-9437-cd029632d3dc?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20210126%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20210126T024506Z&X-Amz-Expires=300&X-Amz-Signature=027d07d89282989316a1690a0720ba0a5e2a14d157fe65785aae3b2586590bd1&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=131628975&response-content-disposition=attachment%3B%20filename%3Didenprof-jpg.zip&response-content-type=application%2Foctet-stream [following]\n",
            "--2021-01-26 02:45:06--  https://github-production-release-asset-2e65be.s3.amazonaws.com/131628975/f5b4b56a-75bc-11e8-9437-cd029632d3dc?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20210126%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20210126T024506Z&X-Amz-Expires=300&X-Amz-Signature=027d07d89282989316a1690a0720ba0a5e2a14d157fe65785aae3b2586590bd1&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=131628975&response-content-disposition=attachment%3B%20filename%3Didenprof-jpg.zip&response-content-type=application%2Foctet-stream\n",
            "Resolving github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)... 52.216.146.179\n",
            "Connecting to github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)|52.216.146.179|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 154714873 (148M) [application/octet-stream]\n",
            "Saving to: ‘idenprof-jpg.zip’\n",
            "\n",
            "idenprof-jpg.zip    100%[===================>] 147.55M  41.5MB/s    in 4.0s    \n",
            "\n",
            "2021-01-26 02:45:11 (37.3 MB/s) - ‘idenprof-jpg.zip’ saved [154714873/154714873]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5vGKmoiQ7-r"
      },
      "source": [
        "from ultrasoundSoundAugmentation.core.CustomDataGenerator import CustomDataGenerator\r\n",
        "from ultrasoundSoundAugmentation.core.Model.LeNet_Functional_Model import buildLeNetModel\r\n",
        "# from ultrasoundSoundAugmentation.core.Model.LeNet_Sequential_Model import buildLeNetModel"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3XvnR6jNn3_D"
      },
      "source": [
        "# 影像大小\r\n",
        "inputs=(256,256,3)\r\n",
        "\r\n",
        "# 若 GPU 記憶體不足，可調降 batch size 或凍結更多層網路\r\n",
        "batch_size=32\r\n",
        "\r\n",
        "# Epoch 數\r\n",
        "epochs=10\r\n",
        "\r\n",
        "# 影像類別數\r\n",
        "num_classes = 10\r\n",
        "\r\n",
        "# log_dir=\"./model/\"\r\n",
        "\r\n",
        "#選擇資料增強的方法\r\n",
        "datagen=CustomDataGenerator(fun=\"Opening_operation\",kernel=10,dtype=int)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NCnTfC9URNPs",
        "outputId": "35372612-5e20-4ab1-b3e1-561c91f2d3b1"
      },
      "source": [
        "train_generator = datagen.flow_from_directory(\r\n",
        "    './idenprof/train',\r\n",
        "    target_size=(256, 256),\r\n",
        "    batch_size=32,\r\n",
        "    class_mode='categorical')\r\n",
        "\r\n",
        "val_generator = datagen.flow_from_directory(\r\n",
        "        './idenprof/test',\r\n",
        "        target_size=(256, 256),\r\n",
        "        batch_size=32,\r\n",
        "        class_mode='categorical')\r\n",
        "\r\n",
        "model = buildLeNetModel(inputs, num_classes)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 9000 images belonging to 10 classes.\n",
            "Found 2000 images belonging to 10 classes.\n",
            "Model: \"lenet_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 256, 256, 3)]     0         \n",
            "_________________________________________________________________\n",
            "conv1 (Conv2D)               (None, 252, 252, 32)      2432      \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 252, 252, 32)      0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 126, 126, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv2 (Conv2D)               (None, 122, 122, 32)      25632     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 61, 61, 32)        0         \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 61, 61, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 119072)            0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 150)               17860950  \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                1510      \n",
            "=================================================================\n",
            "Total params: 17,890,524\n",
            "Trainable params: 17,890,524\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocwgGwqgoIgu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "827a046c-c022-48b8-f1b2-0369f28659e3"
      },
      "source": [
        "# checkpoint = ModelCheckpoint(log_dir + \"ep{epoch:03d}-loss{loss:.3f}-val_loss{val_loss:.3f}.h5\",\r\n",
        "#     monitor='val_loss', save_weights_only=True, save_best_only=True, period=1)\r\n",
        "\r\n",
        "# callbacks_list = [checkpoint]\r\n",
        "\r\n",
        "model.fit_generator(\r\n",
        "      train_generator,\r\n",
        "      steps_per_epoch=10,\r\n",
        "      epochs=epochs,\r\n",
        "      validation_data=val_generator,\r\n",
        "      validation_steps=10\r\n",
        "      # ,callbacks=[callbacks_list]\r\n",
        "      )"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "10/10 [==============================] - 69s 7s/step - loss: 86.1179 - accuracy: 0.1227 - val_loss: 2.4281 - val_accuracy: 0.1094\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 68s 7s/step - loss: 2.4506 - accuracy: 0.1063 - val_loss: 2.3283 - val_accuracy: 0.0938\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 68s 7s/step - loss: 2.3535 - accuracy: 0.0725 - val_loss: 2.3244 - val_accuracy: 0.1063\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 67s 7s/step - loss: 2.3003 - accuracy: 0.1125 - val_loss: 2.3629 - val_accuracy: 0.0938\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 68s 7s/step - loss: 2.3362 - accuracy: 0.1256 - val_loss: 2.3084 - val_accuracy: 0.0906\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 68s 7s/step - loss: 2.3632 - accuracy: 0.0781 - val_loss: 2.3802 - val_accuracy: 0.0906\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 68s 7s/step - loss: 2.3403 - accuracy: 0.0840 - val_loss: 2.3413 - val_accuracy: 0.0875\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 68s 7s/step - loss: 2.3902 - accuracy: 0.0977 - val_loss: 2.3275 - val_accuracy: 0.1063\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 68s 7s/step - loss: 2.3178 - accuracy: 0.1258 - val_loss: 2.3433 - val_accuracy: 0.1437\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 67s 7s/step - loss: 2.3187 - accuracy: 0.1269 - val_loss: 2.3311 - val_accuracy: 0.1125\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f48f8c45828>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    }
  ]
}